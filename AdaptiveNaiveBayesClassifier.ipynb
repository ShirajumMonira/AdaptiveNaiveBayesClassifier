{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaptiveNaiveBayesClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMM9mGVuOIafU46RqoR00F/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShirajumMonira/AdaptiveNaiveBayesClassifier/blob/main/AdaptiveNaiveBayesClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_Lo6MhggAjK",
        "outputId": "f71b167d-ef8a-4693-9951-1618cfb9c4cf"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "#import pylab as pl\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "url='https://raw.githubusercontent.com/sak1b0/Thesis/master/allCSV/nursery.csv'\r\n",
        "\r\n",
        "df=pd.read_csv(url,header=None)\r\n",
        "#print(df.iloc[0,:])\r\n",
        "\r\n",
        "\r\n",
        "#----------to handle nominal values---------\r\n",
        "\r\n",
        "my_arr=[]\r\n",
        "\r\n",
        "#track of column indices \r\n",
        "index=0\r\n",
        "for item in df.dtypes:\r\n",
        "  if(item=='object'):\r\n",
        "    #if data type is nominal adding to the array\r\n",
        "    my_arr.append(index)\r\n",
        "  index=index+1\r\n",
        "  \r\n",
        "print('object data types: ',len(my_arr))\r\n",
        "\r\n",
        "df=df.values\r\n",
        "\r\n",
        "if(len(my_arr)>0):\r\n",
        "  lbl=LabelEncoder()\r\n",
        "  for item in my_arr:\r\n",
        "    df[:,item] = lbl.fit_transform(df[:,item])\r\n",
        "    \r\n",
        "  print('after the conversion: ',df[0])    \r\n",
        "#--------------------------------------------\r\n",
        "\r\n",
        "\r\n",
        "df=np.asarray(df)\r\n",
        "\r\n",
        "X, y = np.split(df,[-1],axis=1)\r\n",
        "#issue here !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n",
        "y=y.astype('float64')\r\n",
        "\r\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.005,random_state=101)\r\n",
        "\r\n",
        "#to check additional info \r\n",
        "debug=0\r\n",
        "\r\n",
        "def debug_me():\r\n",
        "  print('----------debug start----------')\r\n",
        "  print('main data: ',df.shape)\r\n",
        "  print('x: ',X.shape)\r\n",
        "  print('y: ',y.shape)\r\n",
        "  print('x_train: ',x_train.shape)\r\n",
        "  print('x_test: ',x_test.shape)\r\n",
        "  print('y_train: ',y_train.shape)\r\n",
        "  print('y_test: ',y_test.shape)\r\n",
        "  print('----------debug end----------')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "X=np.asarray(X)\r\n",
        "y=np.asarray(y)\r\n",
        "# y=y.ravel() #vector to array\r\n",
        "\r\n",
        "x_train=np.asarray(x_train)\r\n",
        "x_test=np.asarray(x_test)\r\n",
        "y_train=np.asarray(y_train)\r\n",
        "y_test=np.asarray(y_test)\r\n",
        "\r\n",
        "y_train=y_train.ravel()\r\n",
        "y_test=y_test.ravel()\r\n",
        "\r\n",
        "debug_me()\r\n",
        "#==========preprocessing done============\r\n",
        "\r\n",
        "\r\n",
        "#==========optimal number of clusters====\r\n",
        "\r\n",
        "\r\n",
        "no_of_features=x_train.shape[1]\r\n",
        "optimal_k=len(np.unique(y_train))\r\n",
        "#print('no of features: ',no_of_features)\r\n",
        "#print('actual no of classes: ',optimal_k)\r\n",
        "#plt.figure(figsize=(6, 4))\r\n",
        "#from sklearn.cluster import KMeans\r\n",
        "#wcss = []\r\n",
        "#for i in range(1, no_of_features):\r\n",
        "#    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 101)\r\n",
        "#    kmeans.fit(x_train)\r\n",
        "#    wcss.append(kmeans.inertia_)\r\n",
        "#plt.plot(range(1, no_of_features), wcss)\r\n",
        "#plt.title('The Elbow Method')\r\n",
        "#plt.xlabel('Number of clusters')\r\n",
        "#plt.ylabel('WCSS')\r\n",
        "#plt.show()\r\n",
        "\r\n",
        "\r\n",
        "#=================experiment===========\r\n",
        "print(\"optimal no. of k = \",optimal_k,'\\n')\r\n",
        "\r\n",
        "kmeans = KMeans(n_clusters=optimal_k, init = 'k-means++', random_state= 101)\r\n",
        "\r\n",
        "kmeans.fit(x_train)\r\n",
        "\r\n",
        "#print(kmeans.cluster_centers_)  \r\n",
        "\r\n",
        "print('cluster labels: ',kmeans.labels_[0:5,],'\\n')\r\n",
        "\r\n",
        "#creating an array as the index to add column to the main df\r\n",
        "ind_arr=np.arange(len(x_train))\r\n",
        "\r\n",
        "#adding the index column to the data so that i can understand later\r\n",
        "x_train=np.hstack((ind_arr[:, np.newaxis], x_train))\r\n",
        "\r\n",
        "#to see if it has worked and index column is there or not\r\n",
        "#print(pd.DataFrame(x_train[:5,]),'\\n')\r\n",
        "##print(x_train[:5,],'\\n')\r\n",
        "\r\n",
        "##print('-- first column is index --')\r\n",
        "#print(pd.DataFrame(x_train[:5,]),'\\n')\r\n",
        "##print(x_train[:5,],'\\n')\r\n",
        "\r\n",
        "#print(pd.DataFrame(x_train[:5,1:-1]),'\\n')\r\n",
        "##print(x_train[:5,1:-1],'\\n') #without the index here\r\n",
        "\r\n",
        "#mergning y(actual labels with x again)\r\n",
        "##print(len(x_train))\r\n",
        "##print(len(y_train))\r\n",
        "#np arrays have to be in the proper shape to be appended\r\n",
        "y_train = y_train.reshape((y_train.shape[0], 1))\r\n",
        "##print(x_train.shape)\r\n",
        "##print(y_train.shape)\r\n",
        "x_train=np.append(x_train,y_train, axis=1)\r\n",
        "##print(x_train[:5,])\r\n",
        "\r\n",
        "##print(kmeans.labels_.shape)\r\n",
        "cluster_labels = np.asarray(kmeans.labels_)\r\n",
        "cluster_labels = cluster_labels.reshape((cluster_labels.shape[0], 1))\r\n",
        "##print(cluster_labels.shape)\r\n",
        "\r\n",
        "#adding the cluster label column to the data in the last column\r\n",
        "train_data=np.append(x_train,cluster_labels, axis=1)\r\n",
        "#print('basic train data',train_data[:5])\r\n",
        "\r\n",
        "############### working in office lol #####################\r\n",
        "print('my train_data_size: ',train_data.shape)\r\n",
        "cluster_number, occur_count = np.unique(train_data[:,-1], return_counts=True)\r\n",
        " \r\n",
        "print(\"Cluster No: \" , cluster_number)\r\n",
        "print(\"Instance Count : \", occur_count)\r\n",
        "\r\n",
        "#for i in range(len(cluster_number)):\r\n",
        "  #print('Cluster: '+str(cluster_number[i])+' :'+str(occur_count[i]))\r\n",
        "  \r\n",
        "#should not miss these 2 lines and not in the loop\r\n",
        "x_test = np.asarray(x_test)\r\n",
        "y_test = np.asarray(y_test)\r\n",
        "y_test = y_test.ravel()\r\n",
        " \r\n",
        "model = GaussianNB()\r\n",
        "\r\n",
        "#all the predictions of different models will be saved in votes\r\n",
        "votes = []\r\n",
        "weights = []\r\n",
        "\r\n",
        "for index in range(len(cluster_number)):\r\n",
        "  print('==================','working with cluster: ',index, '==================')\r\n",
        "  sub_train_data = train_data[train_data[:,-1] == cluster_number[index]]\r\n",
        "  #print('sub data size: ',len(sub_train_data))  #to see if the sub data is selected propoerly\r\n",
        "  #print(sub_train_data[0:3,:],'\\n')\r\n",
        "  sub_train_data = sub_train_data[:,1:-1]  #index column and last cluster column \r\n",
        "  #print(sub_train_data[0:3,:],'\\n')\r\n",
        "  sub_train_x, sub_train_y = np.split(sub_train_data,[-1],axis=1)\r\n",
        "  #display(sub_train_x[0:3,:])\r\n",
        "  #display(sub_train_y[0:3,:])\r\n",
        "\r\n",
        "  #converting the y to float\r\n",
        "  sub_train_y = sub_train_y.astype('float64')\r\n",
        "\r\n",
        "  sub_train_x = np.asarray(sub_train_x)\r\n",
        "  sub_train_y = np.asarray(sub_train_y)\r\n",
        "  sub_train_y = sub_train_y.ravel()\r\n",
        "\r\n",
        "  model.fit(sub_train_x,sub_train_y) #train\r\n",
        "\r\n",
        "  expected = y_test\r\n",
        "  predicted = model.predict(x_test)\r\n",
        "  #print('predicted: ',predicted[0:5])\r\n",
        "  #print('expected: ',expected[0:5])\r\n",
        "  acc_score = round(accuracy_score(expected, predicted, normalize=True),4)\r\n",
        "  votes.append(predicted)\r\n",
        "  weights.append(acc_score)\r\n",
        "  \r\n",
        "  print('\\nAccuracy: ',acc_score,'\\n')\r\n",
        "  #print(metrics.classification_report(expected, predicted))\r\n",
        "  \r\n",
        "  #print('============================== DONE ================================\\n')\r\n",
        "\r\n",
        "votes=np.asarray(votes)\r\n",
        "print(votes.shape)\r\n",
        "for i in range(len(votes)):\r\n",
        "  print('model ',i,': ',votes[i][0:10], ' weight: ',weights[i])\r\n",
        "\r\n",
        "print('=================================')\r\n",
        "\r\n",
        "\r\n",
        "###########################################################\r\n",
        "\r\n",
        "kmeans.fit(x_test)\r\n",
        "\r\n",
        "#print(kmeans.cluster_centers_)  \r\n",
        "\r\n",
        "\r\n",
        "final_result = []\r\n",
        "for index in range(len(y_test)):\r\n",
        "  final_result.append(votes[kmeans.labels_[index]][index])\r\n",
        "final_result = np.asarray(final_result)\r\n",
        "\r\n",
        "\r\n",
        "print('suggested model: ',kmeans.labels_[0:10,],'\\n')\r\n",
        "print('expected       : ',expected[0:10])\r\n",
        "print('final          : ',final_result[0:10])\r\n",
        "accuracy = round(accuracy_score(expected, final_result, normalize=True),4)\r\n",
        "print('\\nAccuracy: ',accuracy,'\\n')\r\n",
        "print(metrics.classification_report(expected, final_result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object data types:  9\n",
            "after the conversion:  [2 3 0 0 0 0 0 2 2]\n",
            "----------debug start----------\n",
            "main data:  (12960, 9)\n",
            "x:  (12960, 8)\n",
            "y:  (12960, 1)\n",
            "x_train:  (12895, 8)\n",
            "x_test:  (65, 8)\n",
            "y_train:  (12895,)\n",
            "y_test:  (65,)\n",
            "----------debug end----------\n",
            "optimal no. of k =  5 \n",
            "\n",
            "cluster labels:  [1 3 0 4 4] \n",
            "\n",
            "my train_data_size:  (12895, 11)\n",
            "Cluster No:  [0 1 2 3 4]\n",
            "Instance Count :  [3061 2904 1932 2254 2744]\n",
            "================== working with cluster:  0 ==================\n",
            "\n",
            "Accuracy:  0.6615 \n",
            "\n",
            "================== working with cluster:  1 ==================\n",
            "\n",
            "Accuracy:  0.6154 \n",
            "\n",
            "================== working with cluster:  2 ==================\n",
            "\n",
            "Accuracy:  0.8154 \n",
            "\n",
            "================== working with cluster:  3 ==================\n",
            "\n",
            "Accuracy:  0.7231 \n",
            "\n",
            "================== working with cluster:  4 ==================\n",
            "\n",
            "Accuracy:  0.7692 \n",
            "\n",
            "(5, 65)\n",
            "model  0 :  [0. 3. 0. 4. 0. 0. 1. 4. 4. 0.]  weight:  0.6615\n",
            "model  1 :  [0. 1. 0. 4. 0. 0. 1. 3. 4. 0.]  weight:  0.6154\n",
            "model  2 :  [0. 1. 0. 1. 0. 0. 1. 3. 3. 0.]  weight:  0.8154\n",
            "model  3 :  [0. 1. 0. 1. 0. 0. 1. 3. 4. 0.]  weight:  0.7231\n",
            "model  4 :  [0. 3. 0. 1. 0. 0. 1. 1. 1. 0.]  weight:  0.7692\n",
            "=================================\n",
            "suggested model:  [1 3 2 3 0 0 4 1 1 0] \n",
            "\n",
            "expected       :  [0. 3. 0. 1. 0. 0. 1. 3. 3. 0.]\n",
            "final          :  [0. 1. 0. 1. 0. 0. 1. 3. 4. 0.]\n",
            "\n",
            "Accuracy:  0.6923 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        22\n",
            "         1.0       0.58      0.71      0.64        21\n",
            "         3.0       0.75      0.32      0.44        19\n",
            "         4.0       0.22      0.67      0.33         3\n",
            "\n",
            "    accuracy                           0.69        65\n",
            "   macro avg       0.64      0.67      0.60        65\n",
            "weighted avg       0.75      0.69      0.69        65\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCypLhcYg_d9"
      },
      "source": [
        "Double-click (or enter) to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JWnfiUqhDj9"
      },
      "source": [
        "Below attached is the basic Naive Bayesian Model for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHTxSTfUhHyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a310865-7943-4dee-f2ad-73e6d1546258"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "url='https://raw.githubusercontent.com/sak1b0/Thesis/master/allCSV/nursery.csv'\r\n",
        "\r\n",
        "df=pd.read_csv(url,header=None)\r\n",
        "#print(df.iloc[0,:])\r\n",
        "\r\n",
        "#----------to handle nominal values---------\r\n",
        "\r\n",
        "my_arr=[]\r\n",
        "\r\n",
        "#track of column indices \r\n",
        "index=0\r\n",
        "for item in df.dtypes:\r\n",
        "  if(item=='object'):\r\n",
        "    #if data type is nominal adding to the array\r\n",
        "    my_arr.append(index)\r\n",
        "  index=index+1\r\n",
        "  \r\n",
        "print('object data types: ',len(my_arr))\r\n",
        "\r\n",
        "df=df.values\r\n",
        "\r\n",
        "if(len(my_arr)>0):\r\n",
        "  lbl=LabelEncoder()\r\n",
        "  for item in my_arr:\r\n",
        "    df[:,item] = lbl.fit_transform(df[:,item])\r\n",
        "    \r\n",
        "  print('after the conversion: ',df[0])    \r\n",
        "#--------------------------------------------\r\n",
        "\r\n",
        "\r\n",
        "df=np.asarray(df)\r\n",
        "\r\n",
        "X, y = np.split(df,[-1],axis=1)\r\n",
        "#issue here !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n",
        "y=y.astype('float64')\r\n",
        "\r\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=101)\r\n",
        "\r\n",
        "#to check additional info set the value of debug to 1\r\n",
        "debug=0\r\n",
        "\r\n",
        "def debug_me():\r\n",
        "  print('----------debug start----------')\r\n",
        "  print('main data: ',df.shape)\r\n",
        "  print('x: ',X.shape)\r\n",
        "  print('y: ',y.shape)\r\n",
        "  print('x_train: ',x_train.shape)\r\n",
        "  print('x_test: ',x_test.shape)\r\n",
        "  print('y_train: ',y_train.shape)\r\n",
        "  print('y_test: ',y_test.shape)\r\n",
        "  print('----------debug end----------')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# X=np.asarray(X)\r\n",
        "# y=np.asarray(y)\r\n",
        "# y=y.ravel() #vector to array\r\n",
        "\r\n",
        "x_train=np.asarray(x_train)\r\n",
        "x_test=np.asarray(x_test)\r\n",
        "y_train=np.asarray(y_train)\r\n",
        "y_test=np.asarray(y_test)\r\n",
        "y_train=y_train.ravel()\r\n",
        "y_test=y_test.ravel()\r\n",
        "\r\n",
        "\r\n",
        "#model = MultinomialNB()\r\n",
        "model = GaussianNB()\r\n",
        "model.fit(x_train,y_train)\r\n",
        "expected = y_test\r\n",
        "predicted = model.predict(x_test)\r\n",
        "accuracy = round(accuracy_score(expected, predicted, normalize=True),4)\r\n",
        "print('\\nAccuracy: ',accuracy,'\\n')\r\n",
        "print(metrics.classification_report(expected, predicted))\r\n",
        "#print(metrics.confusion_matrix(expected, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object data types:  9\n",
            "after the conversion:  [2 3 0 0 0 0 0 2 2]\n",
            "\n",
            "Accuracy:  0.6469 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      1289\n",
            "         1.0       0.81      0.33      0.47      1273\n",
            "         2.0       0.00      0.00      0.00         1\n",
            "         3.0       0.83      0.57      0.68      1221\n",
            "         4.0       0.08      1.00      0.16       104\n",
            "\n",
            "    accuracy                           0.65      3888\n",
            "   macro avg       0.54      0.58      0.46      3888\n",
            "weighted avg       0.86      0.65      0.70      3888\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}